{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import regularizers\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"TataMotorsTrain.csv\")\n",
    "df1=pd.read_csv(\"TataMotorsVal.csv\")  #Validation-set\n",
    "df2=pd.read_csv(\"TataMotorsTest.csv\")  #test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result']=0\n",
    "df1['result']=0\n",
    "df2['result']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(data):\n",
    "    windowsize = 11\n",
    "    counterrow = 0\n",
    "    numberofdays = data.shape[0]\n",
    "    result = np.array(data['result'])\n",
    "    while(counterrow < numberofdays):\n",
    "        counterrow = counterrow + 1\n",
    "        if(counterrow > windowsize):\n",
    "            windowbeginindex = counterrow - windowsize\n",
    "            windowendindex = windowbeginindex + windowsize - 1\n",
    "            windowmiddleindex = (windowbeginindex + windowendindex)/2\n",
    "            minimum = max(data['Adj Close'])\n",
    "            maximum = 0\n",
    "            for i in range(windowbeginindex-1, windowendindex):               \n",
    "                number = data['Adj Close'].iloc[i]\n",
    "                if(number < minimum):\n",
    "                    minimum = number\n",
    "                    minindex = i\n",
    "                if(number > maximum):\n",
    "                    maximum = number\n",
    "                    maxindex = i\n",
    "            result[minindex] = 1    ## 1 for buy  ,  0 for hold\n",
    "            result[maxindex] = 2    ## 2 for sell\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"result\"]=labelling(df)\n",
    "df1[\"result\"]=labelling(df1)\n",
    "df2[\"result\"]=labelling(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(6,21):\n",
    "    df['rsi' + str(n)] = talib.RSI(df['Adj Close'].values, timeperiod=n)\n",
    "    df['roc' + str(n)] = talib.ROC(df['Adj Close'].values, timeperiod=n)\n",
    "    df['sma' + str(n)] = talib.SMA(df['Adj Close'].values, timeperiod=n)\n",
    "    df['ema' + str(n)] = talib.EMA(df['Adj Close'].values, timeperiod=n)\n",
    "    df['wma' + str(n)] = talib.WMA(df['Adj Close'].values, timeperiod=n)\n",
    "    df['tema' + str(n)] = talib.TEMA(df['Adj Close'].values, timeperiod=n)\n",
    "    df['william' + str(n)] = talib.WILLR(df['High'].values,df['Low'].values,df['Adj Close'].values, timeperiod=n)\n",
    "    df['cci' + str(n)] = talib.CCI(df['High'].values,df['Low'].values,df['Adj Close'].values, timeperiod=n)\n",
    "    df['cmo' + str(n)] = talib.CMO(df['Adj Close'].values, timeperiod=n)\n",
    "    df['macd' + str(n)],df['macdSignal' + str(n)] ,df['macdHist' + str(n)]  = talib.MACD(df['Adj Close'].values,fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df['ppo' + str(n)] = talib.PPO(df['Adj Close'].values, fastperiod=12, slowperiod=26, matype=0)\n",
    "    df['parabolicsar'+ str(n)] = talib.SAR(df['High'].values, df['Low'].values, acceleration=0, maximum=0)  \n",
    "    \n",
    "for n in range(6,21):\n",
    "    df1['rsi' + str(n)] = talib.RSI(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['roc' + str(n)] = talib.ROC(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['sma' + str(n)] = talib.SMA(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['ema' + str(n)] = talib.EMA(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['wma' + str(n)] = talib.WMA(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['tema' + str(n)] = talib.TEMA(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['william' + str(n)] = talib.WILLR(df1['High'].values,df1['Low'].values,df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['cci' + str(n)] = talib.CCI(df1['High'].values,df1['Low'].values,df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['cmo' + str(n)] = talib.CMO(df1['Adj Close'].values, timeperiod=n)\n",
    "    df1['macd' + str(n)],df1['macdSignal' + str(n)] ,df1['macdHist' + str(n)]  = talib.MACD(df1['Adj Close'].values,fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df1['ppo' + str(n)] = talib.PPO(df1['Adj Close'].values, fastperiod=12, slowperiod=26, matype=0)\n",
    "    df1['parabolicsar'+ str(n)] = talib.SAR(df1['High'].values, df1['Low'].values, acceleration=0, maximum=0)  \n",
    "    \n",
    "for n in range(6,21):\n",
    "    df2['rsi' + str(n)] = talib.RSI(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['roc' + str(n)] = talib.ROC(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['sma' + str(n)] = talib.SMA(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['ema' + str(n)] = talib.EMA(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['wma' + str(n)] = talib.WMA(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['tema' + str(n)] = talib.TEMA(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['william' + str(n)] = talib.WILLR(df2['High'].values,df2['Low'].values,df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['cci' + str(n)] = talib.CCI(df2['High'].values,df2['Low'].values,df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['cmo' + str(n)] = talib.CMO(df2['Adj Close'].values, timeperiod=n)\n",
    "    df2['macd' + str(n)],df2['macdSignal' + str(n)] ,df2['macdHist' + str(n)]  = talib.MACD(df2['Adj Close'].values,fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df2['ppo' + str(n)] = talib.PPO(df2['Adj Close'].values, fastperiod=12, slowperiod=26, matype=0)\n",
    "    df2['parabolicsar'+ str(n)] = talib.SAR(df2['High'].values, df2['Low'].values, acceleration=0, maximum=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi=df[['rsi'+str(n) for n in range(6,21)]].to_numpy()\n",
    "roc=df[['roc'+str(n) for n in range(6,21)]].to_numpy()\n",
    "sma=df[['sma'+str(n) for n in range(6,21)]].to_numpy()\n",
    "ema=df[['ema'+str(n) for n in range(6,21)]].to_numpy()\n",
    "wma=df[['wma'+str(n) for n in range(6,21)]].to_numpy()\n",
    "tema=df[['tema'+str(n) for n in range(6,21)]].to_numpy()\n",
    "william=df[['william'+str(n) for n in range(6,21)]].to_numpy()\n",
    "cci=df[['cci'+str(n) for n in range(6,21)]].to_numpy()\n",
    "cmo=df[['cmo'+str(n) for n in range(6,21)]].to_numpy()\n",
    "macd=df[['macd'+str(n) for n in range(6,21)]].to_numpy()\n",
    "ppo=df[['ppo'+str(n) for n in range(6,21)]].to_numpy()\n",
    "parabolicsar=df[['parabolicsar'+str(n) for n in range(6,21)]].to_numpy()\n",
    "\n",
    "\n",
    "rsi1=df1[['rsi'+str(n) for n in range(6,21)]].to_numpy()\n",
    "roc1=df1[['roc'+str(n) for n in range(6,21)]].to_numpy()\n",
    "sma1=df1[['sma'+str(n) for n in range(6,21)]].to_numpy()\n",
    "ema1=df1[['ema'+str(n) for n in range(6,21)]].to_numpy()\n",
    "wma1=df1[['wma'+str(n) for n in range(6,21)]].to_numpy()\n",
    "tema1=df1[['tema'+str(n) for n in range(6,21)]].to_numpy()\n",
    "william1=df1[['william'+str(n) for n in range(6,21)]].to_numpy()\n",
    "cci1=df1[['cci'+str(n) for n in range(6,21)]].to_numpy()\n",
    "cmo1=df1[['cmo'+str(n) for n in range(6,21)]].to_numpy()\n",
    "macd1=df1[['macd'+str(n) for n in range(6,21)]].to_numpy()\n",
    "ppo1=df1[['ppo'+str(n) for n in range(6,21)]].to_numpy()\n",
    "parabolicsar1=df1[['parabolicsar'+str(n) for n in range(6,21)]].to_numpy()\n",
    "\n",
    "rsi2=df2[['rsi'+str(n) for n in range(6,21)]].to_numpy()\n",
    "roc2=df2[['roc'+str(n) for n in range(6,21)]].to_numpy()\n",
    "sma2=df2[['sma'+str(n) for n in range(6,21)]].to_numpy()\n",
    "ema2=df2[['ema'+str(n) for n in range(6,21)]].to_numpy()\n",
    "wma2=df2[['wma'+str(n) for n in range(6,21)]].to_numpy()\n",
    "tema2=df2[['tema'+str(n) for n in range(6,21)]].to_numpy()\n",
    "william2=df2[['william'+str(n) for n in range(6,21)]].to_numpy()\n",
    "cci2=df2[['cci'+str(n) for n in range(6,21)]].to_numpy()\n",
    "cmo2=df2[['cmo'+str(n) for n in range(6,21)]].to_numpy()\n",
    "macd2=df2[['macd'+str(n) for n in range(6,21)]].to_numpy()\n",
    "ppo2=df2[['ppo'+str(n) for n in range(6,21)]].to_numpy()\n",
    "parabolicsar2=df2[['parabolicsar'+str(n) for n in range(6,21)]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=[[j for j in chain.from_iterable([rsi[i],roc[i],sma[i],ema[i],william[i],cci[i],cmo[i],macd[i],ppo[i],tema[i],wma[i],parabolicsar[i]])]for i in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m5in\\anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:373: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\m5in\\anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:374: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "train_images=np.array(train_images)\n",
    "train_images=scaler.fit_transform(train_images)\n",
    "train_images=train_images.reshape(1483,12,15,1)\n",
    "train_labels=df[\"result\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_images=[[j for j in chain.from_iterable([rsi1[i],roc1[i],sma1[i],ema1[i],william1[i],cci1[i],cmo1[i],macd1[i],ppo1[i],tema1[i],wma1[i],parabolicsar1[i]])]for i in df1.index]\n",
    "validate_images=np.array(validate_images)\n",
    "validate_images=scaler.fit_transform(validate_images)\n",
    "validate_images=validate_images.reshape(346,12,15,1)\n",
    "validate_labels=df1[\"result\"].to_numpy()\n",
    "\n",
    "test_images=[[j for j in chain.from_iterable([rsi2[i],roc2[i],sma2[i],ema2[i],william2[i],cci2[i],cmo2[i],macd2[i],ppo2[i],tema2[i],wma2[i],parabolicsar2[i]])]for i in df2.index]\n",
    "test_images=np.array(test_images)\n",
    "test_images=scaler.fit_transform(test_images)\n",
    "test_images=test_images.reshape(306,12,15,1)\n",
    "test_labels=df2[\"result\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Hold','Buy','Sell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=np.nan_to_num(train_images)\n",
    "a=np.amax(train_images)\n",
    "train_images/=a\n",
    "\n",
    "validate_images=np.nan_to_num(validate_images)\n",
    "a=np.amax(validate_images)\n",
    "validate_images/=a\n",
    "\n",
    "test_images=np.nan_to_num(test_images)\n",
    "a=np.amax(test_images)\n",
    "test_images/=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\m5in\\anaconda3\\envs\\opencv-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(12,15,1)))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.25,seed=0))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 13, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 11, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 183,171\n",
      "Trainable params: 183,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "train_labels = np_utils.to_categorical(train_labels, 3)\n",
    "validate_labels = np_utils.to_categorical(validate_labels, 3)\n",
    "test_labels = np_utils.to_categorical(test_labels,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483 samples, validate on 346 samples\n",
      "Epoch 1/100\n",
      "1483/1483 [==============================] - 1s 682us/sample - loss: 1.0209 - acc: 0.5064 - val_loss: 1.1101 - val_acc: 0.4798\n",
      "Epoch 2/100\n",
      "1483/1483 [==============================] - 1s 380us/sample - loss: 0.9636 - acc: 0.5597 - val_loss: 1.1242 - val_acc: 0.5087\n",
      "Epoch 3/100\n",
      "1483/1483 [==============================] - 1s 358us/sample - loss: 0.9648 - acc: 0.5637 - val_loss: 1.0007 - val_acc: 0.5462\n",
      "Epoch 4/100\n",
      "1483/1483 [==============================] - 1s 395us/sample - loss: 0.9356 - acc: 0.5806 - val_loss: 0.9910 - val_acc: 0.5636\n",
      "Epoch 5/100\n",
      "1483/1483 [==============================] - 1s 391us/sample - loss: 0.9387 - acc: 0.5799 - val_loss: 0.9915 - val_acc: 0.5376\n",
      "Epoch 6/100\n",
      "1483/1483 [==============================] - 1s 387us/sample - loss: 0.9168 - acc: 0.5995 - val_loss: 0.9990 - val_acc: 0.5462\n",
      "Epoch 7/100\n",
      "1483/1483 [==============================] - 1s 345us/sample - loss: 0.9225 - acc: 0.5988 - val_loss: 0.9812 - val_acc: 0.5607\n",
      "Epoch 8/100\n",
      "1483/1483 [==============================] - 0s 329us/sample - loss: 0.9123 - acc: 0.5927 - val_loss: 1.0070 - val_acc: 0.5405\n",
      "Epoch 9/100\n",
      "1483/1483 [==============================] - 0s 330us/sample - loss: 0.9088 - acc: 0.6022 - val_loss: 0.9978 - val_acc: 0.5260\n",
      "Epoch 10/100\n",
      "1483/1483 [==============================] - 1s 366us/sample - loss: 0.9029 - acc: 0.6082 - val_loss: 0.9839 - val_acc: 0.5376\n",
      "Epoch 11/100\n",
      "1483/1483 [==============================] - 1s 374us/sample - loss: 0.9090 - acc: 0.6129 - val_loss: 1.0036 - val_acc: 0.5116\n",
      "Epoch 12/100\n",
      "1483/1483 [==============================] - 1s 495us/sample - loss: 0.9046 - acc: 0.6082 - val_loss: 0.9869 - val_acc: 0.5289\n",
      "Epoch 13/100\n",
      "1483/1483 [==============================] - 1s 488us/sample - loss: 0.8959 - acc: 0.6096 - val_loss: 0.9958 - val_acc: 0.5173\n",
      "Epoch 14/100\n",
      "1483/1483 [==============================] - 1s 462us/sample - loss: 0.8983 - acc: 0.6076 - val_loss: 1.0337 - val_acc: 0.5116\n",
      "Epoch 15/100\n",
      "1483/1483 [==============================] - 1s 491us/sample - loss: 0.9012 - acc: 0.6096 - val_loss: 0.9903 - val_acc: 0.5289\n",
      "Epoch 16/100\n",
      "1483/1483 [==============================] - 1s 497us/sample - loss: 0.9028 - acc: 0.6082 - val_loss: 1.0003 - val_acc: 0.5289\n",
      "Epoch 17/100\n",
      "1483/1483 [==============================] - 1s 511us/sample - loss: 0.8870 - acc: 0.6129 - val_loss: 1.0383 - val_acc: 0.5058\n",
      "Epoch 18/100\n",
      "1483/1483 [==============================] - 1s 494us/sample - loss: 0.9020 - acc: 0.6035 - val_loss: 1.0254 - val_acc: 0.4884\n",
      "Epoch 19/100\n",
      "1483/1483 [==============================] - 1s 498us/sample - loss: 0.8899 - acc: 0.6082 - val_loss: 1.0233 - val_acc: 0.5231\n",
      "Epoch 20/100\n",
      "1483/1483 [==============================] - 1s 456us/sample - loss: 0.8948 - acc: 0.6163 - val_loss: 1.0112 - val_acc: 0.5087\n",
      "Epoch 21/100\n",
      "1483/1483 [==============================] - 1s 457us/sample - loss: 0.8901 - acc: 0.6150 - val_loss: 1.0247 - val_acc: 0.5029\n",
      "Epoch 22/100\n",
      "1483/1483 [==============================] - 1s 428us/sample - loss: 0.8829 - acc: 0.6177 - val_loss: 1.0338 - val_acc: 0.4913\n",
      "Epoch 23/100\n",
      "1483/1483 [==============================] - 1s 451us/sample - loss: 0.8863 - acc: 0.6170 - val_loss: 1.0465 - val_acc: 0.5116\n",
      "Epoch 24/100\n",
      "1483/1483 [==============================] - 1s 501us/sample - loss: 0.8939 - acc: 0.6136 - val_loss: 1.0403 - val_acc: 0.4855\n",
      "Epoch 25/100\n",
      "1483/1483 [==============================] - 1s 466us/sample - loss: 0.8854 - acc: 0.6170 - val_loss: 1.0658 - val_acc: 0.4769\n",
      "Epoch 26/100\n",
      "1483/1483 [==============================] - 1s 487us/sample - loss: 0.8919 - acc: 0.6204 - val_loss: 1.1641 - val_acc: 0.4162\n",
      "Epoch 27/100\n",
      "1483/1483 [==============================] - 1s 498us/sample - loss: 0.8726 - acc: 0.6204 - val_loss: 1.1463 - val_acc: 0.4364\n",
      "Epoch 28/100\n",
      "1483/1483 [==============================] - 1s 464us/sample - loss: 0.8760 - acc: 0.6298 - val_loss: 1.0904 - val_acc: 0.4653\n",
      "Epoch 29/100\n",
      "1483/1483 [==============================] - 1s 493us/sample - loss: 0.8740 - acc: 0.6089 - val_loss: 1.1256 - val_acc: 0.4480\n",
      "Epoch 30/100\n",
      "1483/1483 [==============================] - 1s 454us/sample - loss: 0.8633 - acc: 0.6285 - val_loss: 1.1266 - val_acc: 0.4393\n",
      "Epoch 31/100\n",
      "1483/1483 [==============================] - 1s 448us/sample - loss: 0.8676 - acc: 0.6298 - val_loss: 1.2010 - val_acc: 0.4075\n",
      "Epoch 32/100\n",
      "1483/1483 [==============================] - 1s 449us/sample - loss: 0.8743 - acc: 0.6271 - val_loss: 1.2058 - val_acc: 0.4104\n",
      "Epoch 33/100\n",
      "1483/1483 [==============================] - 1s 445us/sample - loss: 0.8762 - acc: 0.6170 - val_loss: 1.1438 - val_acc: 0.4451\n",
      "Epoch 34/100\n",
      "1483/1483 [==============================] - 1s 445us/sample - loss: 0.8683 - acc: 0.6285 - val_loss: 1.1541 - val_acc: 0.4480\n",
      "Epoch 35/100\n",
      "1483/1483 [==============================] - 1s 467us/sample - loss: 0.8608 - acc: 0.6318 - val_loss: 1.1884 - val_acc: 0.4249\n",
      "Epoch 36/100\n",
      "1483/1483 [==============================] - 1s 449us/sample - loss: 0.8650 - acc: 0.6305 - val_loss: 1.1469 - val_acc: 0.4480\n",
      "Epoch 37/100\n",
      "1483/1483 [==============================] - 1s 457us/sample - loss: 0.8591 - acc: 0.6298 - val_loss: 1.2175 - val_acc: 0.4364\n",
      "Epoch 38/100\n",
      "1483/1483 [==============================] - 1s 437us/sample - loss: 0.8547 - acc: 0.6325 - val_loss: 1.1338 - val_acc: 0.4451\n",
      "Epoch 39/100\n",
      "1483/1483 [==============================] - 1s 444us/sample - loss: 0.8599 - acc: 0.6251 - val_loss: 1.1990 - val_acc: 0.4451\n",
      "Epoch 40/100\n",
      "1483/1483 [==============================] - 1s 480us/sample - loss: 0.8562 - acc: 0.6285 - val_loss: 1.1031 - val_acc: 0.5058\n",
      "Epoch 41/100\n",
      "1483/1483 [==============================] - 1s 475us/sample - loss: 0.8598 - acc: 0.6339 - val_loss: 1.1158 - val_acc: 0.4422\n",
      "Epoch 42/100\n",
      "1483/1483 [==============================] - 1s 433us/sample - loss: 0.8485 - acc: 0.6271 - val_loss: 1.1390 - val_acc: 0.4480\n",
      "Epoch 43/100\n",
      "1483/1483 [==============================] - 1s 444us/sample - loss: 0.8489 - acc: 0.6305 - val_loss: 1.1973 - val_acc: 0.4306\n",
      "Epoch 44/100\n",
      "1483/1483 [==============================] - 1s 466us/sample - loss: 0.8465 - acc: 0.6386 - val_loss: 1.1698 - val_acc: 0.4509\n",
      "Epoch 45/100\n",
      "1483/1483 [==============================] - 1s 498us/sample - loss: 0.8402 - acc: 0.6318 - val_loss: 1.1908 - val_acc: 0.4422\n",
      "Epoch 46/100\n",
      "1483/1483 [==============================] - 1s 478us/sample - loss: 0.8519 - acc: 0.6264 - val_loss: 1.2237 - val_acc: 0.4364\n",
      "Epoch 47/100\n",
      "1483/1483 [==============================] - 1s 440us/sample - loss: 0.8446 - acc: 0.6413 - val_loss: 1.1642 - val_acc: 0.4393\n",
      "Epoch 48/100\n",
      "1483/1483 [==============================] - 1s 427us/sample - loss: 0.8350 - acc: 0.6426 - val_loss: 1.2117 - val_acc: 0.4538\n",
      "Epoch 49/100\n",
      "1483/1483 [==============================] - 1s 422us/sample - loss: 0.8368 - acc: 0.6359 - val_loss: 1.2377 - val_acc: 0.4595\n",
      "Epoch 50/100\n",
      "1483/1483 [==============================] - 1s 432us/sample - loss: 0.8383 - acc: 0.6386 - val_loss: 1.2237 - val_acc: 0.4335\n",
      "Epoch 51/100\n",
      "1483/1483 [==============================] - ETA: 0s - loss: 0.8210 - acc: 0.649 - 1s 432us/sample - loss: 0.8196 - acc: 0.6507 - val_loss: 1.2050 - val_acc: 0.4711\n",
      "Epoch 52/100\n",
      "1483/1483 [==============================] - 1s 432us/sample - loss: 0.8280 - acc: 0.6271 - val_loss: 1.1878 - val_acc: 0.4595\n",
      "Epoch 53/100\n",
      "1483/1483 [==============================] - 1s 434us/sample - loss: 0.8321 - acc: 0.6392 - val_loss: 1.2459 - val_acc: 0.4509\n",
      "Epoch 54/100\n",
      "1483/1483 [==============================] - 1s 427us/sample - loss: 0.8325 - acc: 0.6386 - val_loss: 1.2976 - val_acc: 0.4133\n",
      "Epoch 55/100\n",
      "1483/1483 [==============================] - 1s 421us/sample - loss: 0.8161 - acc: 0.6460 - val_loss: 1.2404 - val_acc: 0.4220\n",
      "Epoch 56/100\n",
      "1483/1483 [==============================] - 1s 430us/sample - loss: 0.8171 - acc: 0.6480 - val_loss: 1.2692 - val_acc: 0.4393\n",
      "Epoch 57/100\n",
      "1483/1483 [==============================] - 1s 437us/sample - loss: 0.8251 - acc: 0.6440 - val_loss: 1.2820 - val_acc: 0.4653\n",
      "Epoch 58/100\n",
      "1483/1483 [==============================] - 1s 439us/sample - loss: 0.8246 - acc: 0.6426 - val_loss: 1.2109 - val_acc: 0.4451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1483/1483 [==============================] - 1s 425us/sample - loss: 0.7995 - acc: 0.6554 - val_loss: 1.2572 - val_acc: 0.4566\n",
      "Epoch 60/100\n",
      "1483/1483 [==============================] - 1s 423us/sample - loss: 0.8073 - acc: 0.6507 - val_loss: 1.2078 - val_acc: 0.4538\n",
      "Epoch 61/100\n",
      "1483/1483 [==============================] - 1s 421us/sample - loss: 0.8108 - acc: 0.6507 - val_loss: 1.1616 - val_acc: 0.4855\n",
      "Epoch 62/100\n",
      "1483/1483 [==============================] - 1s 427us/sample - loss: 0.8052 - acc: 0.6480 - val_loss: 1.2570 - val_acc: 0.4682\n",
      "Epoch 63/100\n",
      "1483/1483 [==============================] - 1s 420us/sample - loss: 0.8057 - acc: 0.6507 - val_loss: 1.1897 - val_acc: 0.4538\n",
      "Epoch 64/100\n",
      "1483/1483 [==============================] - 1s 422us/sample - loss: 0.8001 - acc: 0.6548 - val_loss: 1.2132 - val_acc: 0.4740\n",
      "Epoch 65/100\n",
      "1483/1483 [==============================] - 1s 494us/sample - loss: 0.8027 - acc: 0.6548 - val_loss: 1.2653 - val_acc: 0.4480\n",
      "Epoch 66/100\n",
      "1483/1483 [==============================] - 1s 481us/sample - loss: 0.7896 - acc: 0.6595 - val_loss: 1.3227 - val_acc: 0.4509\n",
      "Epoch 67/100\n",
      "1483/1483 [==============================] - ETA: 0s - loss: 0.7901 - acc: 0.648 - 1s 468us/sample - loss: 0.7903 - acc: 0.6480 - val_loss: 1.2646 - val_acc: 0.4566\n",
      "Epoch 68/100\n",
      "1483/1483 [==============================] - 1s 455us/sample - loss: 0.7873 - acc: 0.6655 - val_loss: 1.2723 - val_acc: 0.4711\n",
      "Epoch 69/100\n",
      "1483/1483 [==============================] - 1s 481us/sample - loss: 0.7795 - acc: 0.6581 - val_loss: 1.2452 - val_acc: 0.4480\n",
      "Epoch 70/100\n",
      "1483/1483 [==============================] - 1s 470us/sample - loss: 0.7785 - acc: 0.6467 - val_loss: 1.2436 - val_acc: 0.4566\n",
      "Epoch 71/100\n",
      "1483/1483 [==============================] - 1s 482us/sample - loss: 0.7671 - acc: 0.6662 - val_loss: 1.3028 - val_acc: 0.4682\n",
      "Epoch 72/100\n",
      "1483/1483 [==============================] - 1s 465us/sample - loss: 0.7820 - acc: 0.6527 - val_loss: 1.3264 - val_acc: 0.4393\n",
      "Epoch 73/100\n",
      "1483/1483 [==============================] - 1s 466us/sample - loss: 0.7597 - acc: 0.6696 - val_loss: 1.3652 - val_acc: 0.4451\n",
      "Epoch 74/100\n",
      "1483/1483 [==============================] - 1s 459us/sample - loss: 0.7524 - acc: 0.6655 - val_loss: 1.2979 - val_acc: 0.4595\n",
      "Epoch 75/100\n",
      "1483/1483 [==============================] - 1s 449us/sample - loss: 0.7611 - acc: 0.6730 - val_loss: 1.3939 - val_acc: 0.4538\n",
      "Epoch 76/100\n",
      "1483/1483 [==============================] - 1s 435us/sample - loss: 0.7490 - acc: 0.6682 - val_loss: 1.2841 - val_acc: 0.4509\n",
      "Epoch 77/100\n",
      "1483/1483 [==============================] - 1s 432us/sample - loss: 0.7571 - acc: 0.6804 - val_loss: 1.3341 - val_acc: 0.4162\n",
      "Epoch 78/100\n",
      "1483/1483 [==============================] - 1s 427us/sample - loss: 0.7502 - acc: 0.6689 - val_loss: 1.3249 - val_acc: 0.4422\n",
      "Epoch 79/100\n",
      "1483/1483 [==============================] - 1s 493us/sample - loss: 0.7459 - acc: 0.6784 - val_loss: 1.4259 - val_acc: 0.4277\n",
      "Epoch 80/100\n",
      "1483/1483 [==============================] - 1s 450us/sample - loss: 0.7325 - acc: 0.6811 - val_loss: 1.3874 - val_acc: 0.4624\n",
      "Epoch 81/100\n",
      "1483/1483 [==============================] - 1s 477us/sample - loss: 0.7541 - acc: 0.6736 - val_loss: 1.3922 - val_acc: 0.4595\n",
      "Epoch 82/100\n",
      "1483/1483 [==============================] - 1s 498us/sample - loss: 0.7286 - acc: 0.6824 - val_loss: 1.4040 - val_acc: 0.4595\n",
      "Epoch 83/100\n",
      "1483/1483 [==============================] - 1s 473us/sample - loss: 0.7348 - acc: 0.6709 - val_loss: 1.4013 - val_acc: 0.4538\n",
      "Epoch 84/100\n",
      "1483/1483 [==============================] - 1s 481us/sample - loss: 0.7122 - acc: 0.6952 - val_loss: 1.3555 - val_acc: 0.4624\n",
      "Epoch 85/100\n",
      "1483/1483 [==============================] - 1s 499us/sample - loss: 0.7212 - acc: 0.6784 - val_loss: 1.3378 - val_acc: 0.4566\n",
      "Epoch 86/100\n",
      "1483/1483 [==============================] - 1s 459us/sample - loss: 0.7059 - acc: 0.6898 - val_loss: 1.3802 - val_acc: 0.4538\n",
      "Epoch 87/100\n",
      "1483/1483 [==============================] - 1s 511us/sample - loss: 0.7201 - acc: 0.6831 - val_loss: 1.3770 - val_acc: 0.4364\n",
      "Epoch 88/100\n",
      "1483/1483 [==============================] - 1s 504us/sample - loss: 0.7061 - acc: 0.6891 - val_loss: 1.3798 - val_acc: 0.4393\n",
      "Epoch 89/100\n",
      "1483/1483 [==============================] - 1s 497us/sample - loss: 0.7117 - acc: 0.6831 - val_loss: 1.4012 - val_acc: 0.4566\n",
      "Epoch 90/100\n",
      "1483/1483 [==============================] - 1s 496us/sample - loss: 0.7104 - acc: 0.6891 - val_loss: 1.4075 - val_acc: 0.4364\n",
      "Epoch 91/100\n",
      "1483/1483 [==============================] - 1s 499us/sample - loss: 0.6787 - acc: 0.7087 - val_loss: 1.3959 - val_acc: 0.4682\n",
      "Epoch 92/100\n",
      "1483/1483 [==============================] - 1s 495us/sample - loss: 0.6924 - acc: 0.6925 - val_loss: 1.4535 - val_acc: 0.4509\n",
      "Epoch 93/100\n",
      "1483/1483 [==============================] - 1s 487us/sample - loss: 0.6928 - acc: 0.7047 - val_loss: 1.5147 - val_acc: 0.4451\n",
      "Epoch 94/100\n",
      "1483/1483 [==============================] - 1s 453us/sample - loss: 0.6914 - acc: 0.6945 - val_loss: 1.4776 - val_acc: 0.4451\n",
      "Epoch 95/100\n",
      "1483/1483 [==============================] - 1s 504us/sample - loss: 0.6665 - acc: 0.7181 - val_loss: 1.4768 - val_acc: 0.4480\n",
      "Epoch 96/100\n",
      "1483/1483 [==============================] - 1s 490us/sample - loss: 0.6805 - acc: 0.7026 - val_loss: 1.4319 - val_acc: 0.4422\n",
      "Epoch 97/100\n",
      "1483/1483 [==============================] - 1s 493us/sample - loss: 0.6732 - acc: 0.7040 - val_loss: 1.5868 - val_acc: 0.4277\n",
      "Epoch 98/100\n",
      "1483/1483 [==============================] - 1s 498us/sample - loss: 0.6679 - acc: 0.7020 - val_loss: 1.5861 - val_acc: 0.4393\n",
      "Epoch 99/100\n",
      "1483/1483 [==============================] - 1s 503us/sample - loss: 0.6748 - acc: 0.6966 - val_loss: 1.6504 - val_acc: 0.4335\n",
      "Epoch 100/100\n",
      "1483/1483 [==============================] - 1s 497us/sample - loss: 0.6641 - acc: 0.7161 - val_loss: 1.5121 - val_acc: 0.4162\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=100,batch_size=64, \n",
    "                validation_data=(validate_images, validate_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 - 0s - loss: 1.3116 - acc: 0.5327\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53267974\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 - 0s - loss: 1.5121 - acc: 0.4162\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd3iV5fnA8e+dDYRAAmElLBmyIxCWCwQHuFBRwL0qda/aumqr7a+tVlu1LkSLE8WtqAiWoajICJuwZCeEEYIZhOzcvz+eE8g4gQA5Ccm5P9d1ruQd5z3Pk/He77NFVTHGGOO/Amo7AcYYY2qXBQJjjPFzFgiMMcbPWSAwxhg/Z4HAGGP8nAUCY4zxcz4LBCIyWUT2iMjqSo6LiPxHRDaKyEoR6eertBhjjKmcL0sEbwIjD3N8FNDF85oAvOLDtBhjjKmEzwKBqs4D9h3mlNHA2+osAJqKSGtfpccYY4x3QbX42TFAUqntZM++neVPFJEJuFIDjRo16t+tW7caSaAxxtQXS5Ys2auq0d6O1WYgEC/7vM53oaqTgEkA8fHxmpCQ4Mt0GWNMvSMi2yo7Vpu9hpKBtqW2Y4GUWkqLMcb4rdoMBNOA6zy9hwYDGapaoVrIGGOMb/msakhE3geGAc1FJBn4MxAMoKoTgenA+cBG4ABwo6/SYowxpnI+CwSqeuURjitwh68+3xhjTNXYyGJjjPFzFgiMMcbPWSAwxhg/Z4HAGGP8nAUCY4zxcxYIjDHGz1kgMMYYP2eBwBhj/JwFAmOM8XMWCIwxxs9ZIDDGGD9ngcAYY/ycBQJjjPFzFgiMMcbPWSAwxhg/Z4HAGGP8nAUCY4zxcxYIjDHGz/k0EIjISBFZLyIbReQhL8cjReQzEVkpIotEpJcv02OMMaYinwUCEQkEXgJGAT2AK0WkR7nTHgGWq2of4DrgeV+lxxhjjHe+LBEMBDaq6mZVzQemAqPLndMDmA2gquuADiLS0odpMsYYU44vA0EMkFRqO9mzr7QVwGUAIjIQaA/E+jBNxhhjyvFlIBAv+7Tc9pNApIgsB+4ClgGFFS4kMkFEEkQkITU1tfpTaowxfizIh9dOBtqW2o4FUkqfoKqZwI0AIiLAFs+LcudNAiYBxMfHlw8mxhhjjoMvSwSLgS4i0lFEQoDxwLTSJ4hIU88xgN8A8zzBwRhjTA3xWYlAVQtF5E5gJhAITFbVRBG51XN8ItAdeFtEioA1wM2+So8xxhjvfFk1hKpOB6aX2zex1Pc/A118mQZjjDGHZyOLjTHGz1kgMMYYP2eBwBhj/JwFAmOM8XMWCIwxxs9ZIDDGGD9ngcAYY/ycBQJjjPFzFgiMMcbPWSAwxhg/Z4HAGGP8nAUCY4zxcxYIjDHGz1kgMMYYP2eBwBhj/JwFAmOM8XMWCIwxxs9ZIDDGGD9ngcAYY/ycTwOBiIwUkfUislFEHvJyvImIfCkiK0QkUURu9GV6jDHGVOSzQCAigcBLwCigB3CliPQod9odwBpVjQOGAf8SkRBfpckYY0xFviwRDAQ2qupmVc0HpgKjy52jQGMRESAc2AcU+jBNxhhjyvFlIIgBkkptJ3v2lfYi0B1IAVYB96hqcfkLicgEEUkQkYTU1FRfpdcYY/ySLwOBeNmn5bbPA5YDbYBTgBdFJKLCm1QnqWq8qsZHR0dXf0qNMcaP+TIQJANtS23H4p78S7sR+FSdjcAWoJsP02SMMaYcXwaCxUAXEenoaQAeD0wrd852YASAiLQETgY2+zBNxhhjygny1YVVtVBE7gRmAoHAZFVNFJFbPccnAn8F3hSRVbiqpAdVda+v0mSMMaYinwUCAFWdDkwvt29iqe9TgHN9mQZjjDGHZyOLjTHGz1kgMMYYP2eBwBhj/JwFAmOM8XMWCIwxxs9ZIDDGGD9ngcAYY/ycBQJjjPFzFgiMMcbPWSAwxhg/Z4HAGGP8nAUCY4zxcxYIjDHGz1kgMMYYP2eBwBhj/JwFAmOMqQGbUvdz79RlpGblHdP752/ay4H8wmpOlWOBwBhjasA/Z6zj8+Up3P/hcoqL9ajeuyM9h5veXMzfvl7rk7RZIDDGmGOQX1hMRk5Blc7dsDuLmYm76RUTwQ+/7OX1H49uafYnv1mHKtx+VudjSeoR+TQQiMhIEVkvIhtF5CEvx38vIss9r9UiUiQiUb5MkzHGHC9V5ea3FjPiX99VqOpRVXILisrse+W7TTQMCeSdmwYxsmcr/jljPSuS0qv0WYu27OPLFSncOrQTMU0bVFseSvPZmsUiEgi8BJwDJAOLRWSaqq4pOUdVnwae9px/EXCfqu7zVZqMMaY6fLtmNz/8sheAhz5ZyevXxyMiFBcrv/94JTNW7+Slq/sx7OQWbE87wLQVKdx0WgciG4Xw5JjenP98Ore9u4QebSLYkZ7L3v15xEY2oFurCLq3bsyoXq2JbhxKUbHyxJeJtG4Sxq1DO/ksP74sEQwENqrqZlXNB6YCow9z/pXA+z5MjzHGHLfcgiL+9vVaurYM59HzuzN73R7eX5SEqrtpf7I0mUahQfzmrQQ+XpLMK99vIlCE35xxEgBNG4bwwlV9CQsOJPnXHNo0CWNY12hCAgOYvmonf/oikdOfmsOfv1jNK99tJDElk4fP706DkECf5clnJQIgBkgqtZ0MDPJ2oog0BEYCd1ZyfAIwAaBdu3bVm0pjTL1WUFTMRwnJjOrVishGIcd9vck/bWH7vgNM+c0ghpzUjO83pPLXr9awOiWD9xZu55YzOnL3iC7c9u5SHvhoBYEBwvgBbWkZEXbwGv3bRzHngWEVrq2qbErdz6R5m5mycDuFxUp8+0gu6tP6uNN9OL4sEYiXfZU1lV8E/FRZtZCqTlLVeFWNj46OrrYEGmPqv8+W7eCRz1bx+49XoFr2FpRfWFxh3+HszszlxTkbObdHS07r3JyAAOGZK+IICQrgvYXbGRfflkfO707jsGAm3zCAS/vGEBYUUOVqHRGhc4vG/PPyOL7/w1ncf05XnrkiDhFvt9Pq48sSQTLQttR2LJBSybnjsWohY0w1Ky5WJn6/iQbBgcxau4fPlu3gsn6xACxPSuf6yYs4uVVj/jK6J91aRQAwf+NeXvpuI5ENQ7jvnK50ig4HIDElgz99kUhhkfLoBd0PfkarJmG8cnU/FmxO456zux68aYcEBfDsuFPIyS86pmqdmKYNuHtEl+P9EVSJHE00PKoLiwQBG4ARwA5gMXCVqiaWO68JsAVoq6rZR7pufHy8JiQk+CDFxpi6rrComKDAQxUdMxN38dt3lvDcuFOYsnAb63dl8e19Q9mTlcvVry8kIiyY7PxCsnILuXpQO7amHWDehlRaRYSRlVtAbmExY+Njyckv4vPlKTRpEMyfLuzBmP6xtZjLYyMiS1Q13tsxn5UIVLVQRO4EZgKBwGRVTRSRWz3HJ3pOvRT4tipBwBhTvy3Z9isZOfkM79aywrGMAwUkbNvHoq37yMot5I6zOh/sTllYVMzTM9fz1s9b+dcVp3BBn9aoutJA26gGXNinNae0bcrI5+dxx3tL+WV3Fk0aBPPBb4fQMDiQZ75dzzsLttGkQTB/vKA71wxuz/68Ql6cs5EpC7cRGCDcPqwTvx3aiSYNgmv4p+J7PisR+IqVCIypnxZuTuO6yYvIKyzmH5f15sqBrmNIQVExT3yZyJSF21GF4EBBRAgJDODh87txTveW3PX+MhZu2UfrJmHsycrjxSv7EtUohHGTFvDX0T25dkgHAN74aQtPfLmGmKYNmDphMG2jGh78/F0ZuYSHBREeWvb5ODUrj8AAIaoaGppr0+FKBBYIjDE1SlX535rdKDCiWwuCAgNYvSODKyctoEVEKDGRDZm3IZV/junDOT1acvuUpfy8OY1rBrfjgt5t6NuuKXsy83jo05XM35RGSGAAAQHw90t7c27PVlw/eRErktJp36wh6QcK+Omh4YQFuzr64mLlg4Qkzuwa7bPBWSeq4woEInIhMF1Vi32RuKNlgcCYukFVeXP+VhqHBXNez5Y0DgtmR3oOD3+6inkbUgFoFRHG5f1jeW/RdhoEB/LxbUOIbBjChHeW8MMvqbRsHMa+7HyeHNP7YCNv6etPXZzE9FU7eeT87nRv7Rp7s3ILuPa/i1ielM4D53blzuE10+B6ojveQPAuMAT4BHhDVX0z61EVWSAwpuZk5hYwfeVOLoprQ6NQ702KuQVFPD/7F8b0i6Vzi/CD+z9ftoN7P1gOQGhQAGd0iebnTXtR4MGR3Yhp2oC3F2xj3oZUmoeH8NGtp9KxeaOD15zwzhLWpGTy6rX96N/+6Gaeycwt4NMlyYwd0JaGIb7sHFl3HHfVkIhE4Eb+3ogbC/AG8L6qZlVnQqvCAoExNefu95cxbUUKsZENeGpMH07r3LzCOS/M/oV//W8DsZEN+PyO02geHsruzFzOfXYenaIb8cj53flieQozEnfRvXUEf7ukV5m6+aR9BwgJCigz4ArcE39BkRISZHNjVodqaSMQkebANcC9wFqgM/AfVX2huhJaFRYIjKle63dl8c6Crez4NYd/jT3lYKPonHW7uenNBC7rG8OypHS27M3myoHt+PNFPQ7Wue/MyGH4M9/To00Eq3dk0DumCe/+ZhB3TFnKjxv38s09Z3BSdPjhPt7UkOPqPuqZDO4moBPwDjBQVfd4poVYC9RoIDDGn+XkF/HEl4nERjZg3IB2RDcOrfJ7M3IKmLl6Fxt2HyrIr9yRwaIt+w4+dV/9+kLe+80gggKFRz9bTdeW4Tw5pg/Fqjz7vw1M+mEzO9JzmHRtf8KCA3nqm3UUqfLcuFNYkZzOne8t49KX57N2ZyaPXdjDgkAdUZXKsyuAZ1V1XumdqnpARG7yTbKMqZu27s0mdX8eAzpU/2zqRcXK3VOXMWvtblTh+dm/cH7v1vRsE3HwnJimDRnQMZIWjV01S0p6Dou37mNm4i5mrd1DfmExYcEBBHpGv7aICOOhUd0YG9+W1Tsy+M3bCVzz34V0axXBrsxcXrr61INB4uHzu9MpOpw/fLKS295dwoQzO/H58hTuGt6ZtlENaRvVkE17snl21gYGdojixlM7VPvPwPhGVRqLOwI7VTXXs90AaKmqW32fvIqsasicqH7ZncXYV38mO7+IH/9wFi3K1Xl7o6qs3ZlFYkoG63dlsSM9h1M7NeOCPm3K9FtXVf70RSLvLNjGX0b35NROzZmycBsfL0kmK7fi8oUdmjWkoEjZkZ4DQPPwEC7s04ZL+sYQF9uk0rlrvlu/hwlvLyG/qJgbT+vAny/qWeGc9xZu55HPVhEUIDQPD2XOA0MPNsiqKl8sT+HUzs0OBiNzYjjeXkMJwKmeqaQRkRDcBHEDqj2lVWCBwNS04mJlb3YeO9NzaRfV0OsMlkn7DnDFxJ8pLC5mX3Y+N5/ekUcv6HHY6+7MyOGRT1cxd73rShkaFEDz8FB2pOcQFCCc0aU5PdpEENO0IdvSsnl13mZ+O/QkHh51aJ6bwqJi8gpdz+5iVTbu2c/irftYtOVXggOFAR2iGNgxiu6tIwgMqNrEZd9vSOWzpcn87dLelfYUemfBNh6flshz407horg2VbquqV3HGwiWq+op5fatUNW4akxjlVkgMNVlX3Y+kQ2DK306zi0o4rZ3l/DTpjTyPTfbxqFB3HdOV64b0v7gnDa7M3MZ9+rP7MvO54PfDuHV7zfx7Zrd/PTg8INBIzuvkPmb0ggLDqBxWDCrd2Tw1DfrKCxW7j27C2f3aEmHZo0IEFi7M4svlu9gZuIukn7Nocizvu3FcW14btwpBFTxhu5r2XmFlQYKc+I53rmGUkXkYlWd5rnYaGBvdSbQmJqUX1jMv/+3gVfnbWJghyj+MroXJ7dqXOG8v3y1hrnrU7luSHs6RYfTonEo7y3azl++WsOHCUkMPqkZi7fuY+3OTEKDAnn3NwPp3jqC28/qzOfLU3hj/lbuP6cr2XmFXP36QpaXW5pwyEnNeGpMH9o1a1hmf482EfRoE8HD53ensKiYPVl5/Hogn+6tIk6YIABYEKhHqlIi6ARMAdrg1hhIAq5T1Y2+T15FViKon4qKlZXJ6WTnFRET2YDWTcIOdlEEV/ectC+HRVv3ERQgXBTXxmtVR2pWHpN/2sLiLfu44bQOXNC7dZkn/s2p+7ln6nJW7cjg3B4tD05gdt2Q9twzogtNG7on+JLBUOWrYlSVb9fs5q9frWHv/jz6tYtkQIcozu/dukwwmfB2Ags2p/Hd78/i7veXMX/TXp4c04cOzRqRlVtASFAAp3VqfkLd2E39Vl3jCMI959f4ILLSLBDUvp83pbkn44t7lqkvLy5Wvl61k7U7M0lJz2F3Zh4doxsxqGMUAzpE0cbL3C4/b0rj4yXJfLd+D2nZ+WWORYQFEdEgmMZhwfyanc+uzNyDx/q1a8o/L4+jc4twVJXElEw+Skhi6uIk8ouKadOkwcGG19+d25VNqdnMXrub79an0iAkkCcv68PIXq34NTufp79dz/uLttMwOJCrB7dn2MnR3PxmAr1jmvDeLYPKTGtcQlUpKlavxwBWJqdz8Ys/0SoijF2ZuTxzRRyX18Gpi039UR0jiy8AegIHuwGo6l+qLYVHwQJB7Xp/0XYe+3w1hcVaoVfJh4uT+MMnKwkKEFo1CaN5eCib9uwnK8/1arlqUDv+cnHPgzfPL5bv4L4PlhPRIJhhXaMZ3r0l0eGhpKTnsCM9h7T9eWTlFpKZW0DDkCAGdIhkQMco1u7M5PFpa8gpKOKcHi1J2LqP3Zl5BAcKl/aN4dahnWjfrBHvLdzG0zPXk+npVdO6SRgjurfgjrM607pJ2aC0flcWL3+3kS9XpFCsrpfN13efUWG069G49r8L+eGXvfzpwh7cdHrHY76OMdXheBuLJwINgbOA14HLgUWqenN1J7QqLBDUnAP5hWzak416Vhj9fFkKk3/awtCu0TRtGMz0VTuZ87thtI1qSFZuAWc98x3tmzXigwmDD97si4qVtTsz+WRpMm/8tJWzu7fghSv7MWvtbu6ZuoyBHaN444aBR72C056sXB6flsjPm9IY0qkZw7u1ZNjJ0TQPLzvAKm1/HrPW7qZ3TFO6t258xCX/tu7N5r1F2xnZqxX92kUeVZoqpDEzl8SUTM7q1uK4rmNMdTjeQLBSVfuU+hoOfKqq5/oisUdigeDIcguKUOXgzVVV2Zp2gMVb95GZU0DjsCAahwXTvllDerSOKHNz3JGew5y1u5m9bg/zS/WWKXHTaR155Pxu7N2fz7Bn5nJez1Y8P74v/5i+lkk/bGbaHafTO7aJ13S98/NW/jQtkS4twtmUmk3/dpG8edMAmxTMmBpwvL2GSipmD4hIGyANsHLuUcjJL+JAfiHNwqs+HUBldqTn0KZJWKVPttNX7eThT1eRkVNAs0YhtG4axq6MPPbuz/N6fquIMIZ3b0HTBsHMWbeHdbtcE1D7Zg25ZlB7BnaMJNjzdB/VKIS+nqfkVk3CuOm0jrz83SbO6dGSyT9t4Yr+sZUGAYBrh3QgunEod09dTt+2TZl8owUBY04EVSkRPIabT2gE8BJu9tHXVPVPvk9eRXWpRLA5dT/vLHCjP/fnFTKiWwuuGdyeM7tEk5VbyI70HLLzC+kcHX6w0VVVScnIJWnfAZqHhxLTtAEiMG1FCu8u2MbK5AxG9WrFv8bGlbmJZucV8vi0RD5akkxcbBPO7t6SlIwcdqTnEtUwmAEdoxjYIYoWnrVYs3ILWb0jg9lr9/DDL6nkFhYT3z6SEd1bMLxbSzpFNzpiNUpGTgFDn55LRk4BjUKCmPPA0CqNJt2TlUvTBiE2q6QxNeiYq4ZEJAAYrKrzPduhQJiqZlTxg0cCz+PWLH5dVZ/0cs4w4DkgGNirqkMPd826EAjW78ri6ZnrmbV2N8GBwqherYmJbMBHCUns3Z9PSGAA+UVlq1xaRoTSqkkDNqfurzBlQHCgUFCkdG4RzqCOUby3aDs920Tw+nUDCAsO4KOEZN6cv5WUjBxuH9aJe8/uevApviryCosoKNIKS/RVxes/bOb/vl7Lw6O68duhnY76/caYmnG8bQQ/q+qQY/jQQGADcA6QDCwGrlTVNaXOaQrMB0aq6nYRaaGqew533RM5EOzMyOFf327gk6XJhIcEcfMZHblqULuDT8l5hUXMWL2LlckZtIoIIyayAQ1CAtm4ez9rd2WyKyOXk6IbcXKrCNpHNWRfdj470nPYl53PiO4tGHJSM0SE2Wt3c/f7ywgJCuBAfhF5hcUM6BDJ7849mcEnNavRPBcV68EG26pOYWCMqXnHGwieAFbiGoirvMCxiAwBHlfV8zzbDwOo6j9KnXM70EZV/1jV69ZWIPh4STIp6TlEeBpaB50URWzkoRGhCzanceu7SziQX8T1Q9pz+7DOXuekqS7rd2Xx0Kcr6dYqgmsHt6dHqRkojTGmvONtLL4faAQUikgubnSxquqR7jwxuFHIJZKBQeXO6QoEi8h3QGPgeVV920sGJgATANq1a1eFJFevhZvTeOCjFWX2BQcKVw9qz13DOzNr7W4e/Ww17Zs15LPbBxxcbs+XTm7VmM9uP83nn2OMqf+OGAhUteIkLFXjrZ6gfIkiCOiPa4huAPwsIgtUdUO5NEwCJoErERxjeo5JUbHyxJdraNMkjBn3nUlhkbJ3fx5v/LSFdxZs4/1F28krLObMrtG8eFVfIsKCazJ5xhhz3KqyQtmZ3vaXX6jGi2SgbantWCDFyzl7VTUbyBaReUAcrm3hhPBhQhJrdmbywpWHbvJRjUL4x2V9uPn0k3hhzi+0btKAB87tWul0A8YYcyKrStXQ70t9HwYMBJYAw4/wvsVAF8/CNjuA8cBV5c75AnhRRIKAEFzV0bNVSFONyMgp4JmZ6xnQIZIL+7SucLxzi3CeH9+3FlJmjDHVpypVQxeV3haRtsA/q/C+QhG5E5iJ6z46WVUTReRWz/GJqrpWRGbgGqOLcV1MVx9DPqqFqvLDL3tJ94y+nbFqF/sO5PPWRQOP2KfeGGPqqmMZ1pkM9KrKiao6HZhebt/EcttPA08fQzqq3efLd3DfB2UbhccPaEuvmMpHyxpjTF1XlTaCFzjUyBsAnAKsqPwdddPuzFwen7aG/u0jeWpMbzJzCzmQV0T/9sc38ZgxxpzoqlIiKN1pvxB4X1V/8lF6aoWq8sinq8grLOLpy/twUnR4bSfJGGNqTFUCwcdArqoWgRsxLCINVfWAb5NWcz5ZuoPZ6/bw2IU9LAgYY/xOVfo7zsb18S/RAJjlm+TUrKR9B3hxzi88MS2RgR2iuLFfJHx+O+xZW9tJM8aYGlOVEkGYqu4v2VDV/SLS8HBvONFlHCjg1neX8PPmNAAGdojiX2PjCJj1ECyfArkZMH6K9zfnZcG7l8NJQ+GsR2ow1cYY4xtVCQTZItJPVZcCiEh/IMe3yfKtb9fs4ufNadw1vDNj49vSNqohbP4elr4FjVvDuq9h3xaIKrfsgip8cQckLYDkxdDrcojuWjuZMMaYalKVqqF7gY9E5AcR+QH4ALjTt8nyreVJ6YSHBnHf2V1dEMjPhml3QdRJcMPXEBAIi16r+Mb5L8CaL+C0eyG4IfyvVpZkMMaYalWVAWWLRaQbcDJu/qB1qlrg85T50IrkdPrENiGgZNrkOf8H6dvghunQrBP0uASWvQNnPQyhnqmWtsyDWX+G7hfD2Y9DWBOY/YTb39HrLBzGGFMnHLFEICJ3AI1UdbWqrgLCPdNH10m5BUWs25nFKW2buh17N8KCVyD+Zujgmc1z8G2QlwnL33Pbv8yCD66FZp3hkpdBBAbfDk3awsxHoLiodjJjjDHVoCpVQ7eoanrJhqr+CtziuyT5VmJKBoXFSlxJIFj3JaBwxu8OnRQbDzHxsHAizP07TLkcImLgqg8PlRCCw1zJYNcqWPF+DefCGGOqT1UCQYCUmmjHs/KY71Zc8bHlSW6VzYMlgvUzoFUfaBJT9sTBt8G+zfD9UxB3JfxmVsXG415jIHYgzHgY0jaVPbbiA1g4yUe5MMaY6lOVQDAT+FBERojIcOB94BvfJst3ViSl07pJGC0jwiA7DZIXwcmjKp7YYzT0GQ8Xv+iqg0K89JgVgTGvu8blD651jc7gGpo/mwAzHoL0pIrvM8aYE0hVuo8+iFsd7DZcY/EyoOKczHXE8qR04mI9pYFfvgUthq4jK54YGAyXvXrkC0a2hzH/hXfHwJf3QIfTYfoD0HEobP0RFr8G5/zl0Pl5WZC2EdocZvrq4iLYONu1UwAEhblgFRBY9YwaY0wVHbFEoKrFwAJgMxCPW02sTg693Zedz/Z9BzilnScQbPgGwltB61OO78KdR8DwR2HVRy4YdD4Hrv4Iul8IS946VFJQhQ+vg0nDYGmFFTkP+f6f8N4V8MnN7vXB1ZAw+fjSaIwxlag0EIhIVxH5k4isBV7Es/6wqp6lqi/WVAKr04pk1+YdF9sUCvNg4xzoeh4EVMPKYqf/DuKuct1Lx70LQaEw6DbITYeVH7hzlr8Hm+ZA03Yw7e5DvZJK250IPzwDPS+DOxa7V+xA+PE5KMz3/tmq8M2DsOHb48+HMcbvHO4OuA739H+Rqp6uqi8Adbqf5PLt6YhA79gmrtomP8t7+8CxCAiAS1+Bce+4HkUA7Qa70saCiZC5E2Y+DO1OhdsXuikqPr8dVn546BpFhW7kclhTOP8ZN2o5uisMfRAyk2GFl8ABkLLU9XD66AabJ8kYc9QOFwjGALuAuSLymoiMwPuC9HXGiuR0urZoTHhoEGyY4ereOw713QeKuN5He9fDWxe5UsjFL7iG5/Hvu/aET2+B96903VAXvAQpy+D8p6FRs0PX6TzCtSn88G8o8jKWb800CAhy1/3gGjdXkjHGVFGlgUBVP1PVcUA34DvgPqCliLwiIufWUPqqjaqyIimduLZNXFXK+hlw0jDvvYGqU89LoVELSPsFhj0MzTu7/SEN3biEsx6FrT/BxNNh9l+g24XuPaWJuFJB+jbXDlE2Y27ai45nwhVvuTmSPr/d7T+cddNdF1djjN+rSmNxtqpOUdULgVhgOfBQVS4uIiNFZL2IbKKnw0EAACAASURBVBSRCu8RkWEikiEiyz0vn03es33fAX49UOAGku1OhIzt3nsLVbegUDj3/6D3WBhSboqmkIYw9A9w70o48w8QOwAu+Je78ZfXdSS06g3znik7knn3avh1i+vu2uE091nrvoLPbq2862r2Xvjst/Dl3a4LrTHGrx1VK6mq7lPVV1V1+JHO9Qw8ewkYBfQArhSRHl5O/UFVT/G8/uLleLVYnuQaik9p29SNBA4Ick/fNSFuHIx5DQIr6a3boKnrdXTTDGjcyvs5InDm72HfJlj27qH9a74ACTiUl8G3wen3QeKn8EI/+PoB2L+n7LW++4fryVSYC0vfPO7snRDWfAFPd4G8/Uc+1xhTRjV0l6nUQGCjqm5W1XxgKjDah593WEO7RvPadfF0bRbiAsHJ50N4dG0l59h0uwjanwbfPuYan8G1D7Q/DRo1d9sibuqLu5bCKVfBkjfg9bMhI9kdT10PCW9A/I2uamzR697bHeqaTXMge48r7RljjoovA0EMni6nHsmefeUNEZEVIvKNiPT0diERmSAiCSKSkJqaekyJadowhHN6tCR44ww4kAb9rj+m69SqgADX2FyUB1//Dvascw3RPbzE16Zt4aLn4eZvIedXePNCyExxU2eHNHLtFYNug6wUWDut5vNS3Xatcl/3WCAw5mj5MhB462FUvgVzKdBeVeOAF4DPvV1IVSeparyqxkdHH+dT/JK3ICIWOp11fNepLc06uZXR1n8N0+4E5PBVXDH94ZpPXbvAa8Ndb6kz7ncliC7nujUYFrxSY8n3ieIi2L3GfW8lAmOOmi8DQTLQttR2LJBS+gRVzSxZBlNVpwPBItLcZyn6dStsngt9r6nb0zUMvsN1J01e7MYqRBxhxo+2A9xI59xMaNLOlQTAlTAG3equk7zE9+n2lbRNUOhZNK8kIBhjqsyXgWAx0EVEOopICDAeKFMHISKtSmY2FZGBnvT4rhvLsimAuEBQlwUGweiX3DiI3ldU7T3th8CtP8ANXx0a8AauHSE0An78NxQX+ya9vrZrpfsaO9CVCI7Udba+Wv0pJC2q7VSYOshngUBVC3FLWs7EzU30oaomisitInKr57TLgdUisgL4DzBe1Uf/xcVFrrdN5xGu/ryua9kTfrce+t9Y9fc06+QmySsttDEMucN1OX1/PBzYV73prAm7VkFAMPS6DPIyIHNHbaeo5uVmuC7DU6+qm79DU6t8WSJAVaeraldV7aSqf/Psm6iqEz3fv6iqPVU1TlUHq+p8nyVm42zXMNrvOp99RI1r0LR65kka+qCb0mLTHHh1KOxYevzXrEm7V0OLbocmD/THdoI101wnguy9bn0MY46CTwPBCSWyg6sb71pNcwvVJyIw8Ba4aSagbkW2ulRNtGsVtOwNLT3DVPwxEKz8AKI6wZkPwMqplU9AmLYJkhNqNm3mhOc/gSC6K4x6EoLq7OJqvhfb35UODqS50cp1wf49sH+3G3Ud1sStI12bgSBpkVuZribbKTJT3CSKfca6QYfR3eCre13ngNKKClz139uXVDxWmfTtblr0gtzqT7c5YfhPIDBV06q3+1rSAFuZ4hNkItqS8QMl6W7ZE/bUYs+hbx+Db37vqmeONxhUtVS26mNAXceBoFC3ql5mCsx8pOx5S96EvRvcrLvepkAvL/+AmxBx7t8Ov35G2iZ45zJIWV619NYXi/8Ln99RLzonWCAwZUV3AwmEXasrP2fTHPhH7InR5fRgIOjlvrbo4W52la3d4EslS582bQcLX4H/PXbsN4nUDe5nvPbLI5+76kM3XqRZJ7fddoCbZmTZO4emI8nNcFOLtD/d9a5aOPHwwVzVlSp2J7pq1R+fdbPnlrdvi5tZd9Nsd05NKMyDHUuqXkpRdUHKW/qPVXERzHsalr/rAmwdZ4HAlBUcBtEnH7rBerPwVSg44NZOqM5/rmOxa5WrDmoQ6bZb9oTiQhcMfKW4GNZ9XbGuvWTp0yvehAG3wPwXYNbjx9besuBlKMh2T/WHu+HtWed+Br3Hlt1/1qNuRtqv7nc3wR/+7ar8zvs/Nx/Vr1tceiuz+HXX7nDWo3Dhs66jxfIpZc9J3w5vXez+FrqOcj+T7L2VX3Pd164K63j9+JwbHPlkOzdiftYT8N1T7jX/hbJza+Vnw6cTYNJQ+E8/N71KdUypsvVHyNoJDZu7UmBG3e6pVpU1i42/adUbtvzg/VhmiruBtDsVts+HH/7lRjrXll2rDlULAbT0lAx2Jx4qJVQXVdfNdu4/3FQWjVvDvavc+tZQaunTvu5VXAg/Pefmd7r0lUPB6kgO7IMVU12+dq2CRa/Cafe4Y/nZMPfvbqLBjkNd6UwCXdfZ0gKD4PI34NUz3RoV+/dAn/FuIGLLXhAR40aUl1+YqajQ3fBnPORu7mf8znUmiIl3T/x9r3X53fuL61SQlwHXTYPAEJf/FVPh1HKz7IKb9nzqVe77DmfA8D+6wZDHIvFT97PpOBS2fO8piZQqec39u+v8cPIFbobd1PUw+HbXfvPVve78XmNcoGw76MhT0S/+r2t/6n35oX2rPoSQcDcu57Xh8NV9cNUH3mcOrgOsRGAqatnLPQF6m6J62RT31HvJS9BnnAsEh6tG8qWCHLfOQ+lA0KyTuylVZc6hkrWkq6KoAN651N1Ui/LclOJZO92sp+BZ+nQ2nDzSdekNCHBP0qOeho2z3A05ZVnVPmvp226k9CUT3TQg8/7lfhcFOa7O/ueX3E18yhi3mNFJwyC8RcXrNGoOY99xjekSACMec/sDg2HAb9xNtKRhvajArU/x0gB382zTFy6d6PIh4qZLT9/uSgmrP3XrbudlwTWfQZtTXI+t2AEu7eWrw9I2uWnPW8fBef9wN+bJ58HEM2Dmo7BhpstbVaSuh9R10Pc6OO9vcOuP8Kd98Kdf3evOJW7KlZ/+A5PPdSWUaz+Dkf+A38yCqz6CJrHw0/PwziXwVHvPQNNKbP0Jvr7flX5LJm4syHXddbtfBC26w/DH4JeZFdcKqUMsEJiKSm6su8tVDxUXw7K33ZNU1Ekw8kn3lPvFHcdW3M7bD5vmQtauiscykt2UIIezZ40LSi1LPfkHBruqrZIbXH42bP6+YvXMzhXwVEf46EZ3QzuSb//opicZ+aRbavScv7rumiXzNG39EfL3l+2eLAKDJsCN37jPf/PCI68eV1QIi15zT82ternPyd8Ps5+AqVfDlnlwySvw0DZ3gxv2MJzzROXXi+3vnlTHvuVugCX63wBBDVzV0btj4Mn28NkECG7kVs+7+X9unEqJLue6G/k3D8LHN7q2mN/+4K5fot/1bhLE0qOb87Phg2vdlC5j34Eht8M9K+C8v7sR7YsmwXtj3e+hKtZ4JifoftGhfSWBNyDALfw05jW4fYHrAffbeYfmFROBrufCjdPdz+/qj6FNP5j+e/h1W8XPKsiBaXe5qkdVt3AUuJt+XuahUf2DfuvaXb6403USyNpd8VqqsHejeyiojfarI7CqIVPRwZ5Dq9zTZokt37unwhF/dtsNo9xAtI+udze5K96AiDZHvv7St2HpO26t5eJCV8100zeHjhcVurrn/bvdza7twEPHtv7kaUBVSNtYNr0lWvSEzd+5J+cfn4XsVBj5FAz2DGhXdU+iAUGw5nM3IG3s2+7pzpuVH7nG1cG3u/r1EoNudT2EkhM8S582cGtRl9d2AIx5Hd4Y6UoN5atxSlv3pVuf+vynPXnp5m7aCf912xe/CKdc6b7vNNy9jsTbOQ2joN+17kYc3c1NNdLlHOh8jvdBiiKuveC9ce7ncPYTFbti97zUVSktfRvaDXJVXF/e7QL2NZ8cGtUe0tCNZh9yh7vZ/u9Prk1i/x7vJZvS1nzhqnOONL9Wi27Q4jBVlqGNXX6ju8HLg12V0TWflq3amft3t/7HdV+4v6cfn3W/85UfulUHS5a5DQiEce+6QLHwVdcO0WsMhIa74wf2edoUPFOtNW3vglSfcZWvUVLDrERgKmrU3NV/l28wXvq2KwGUnu205yVw2evu3FfPdP8wh5OZ4p6y8rLg1LvdIL/t88s2IiZ+6v4BA4Lc02ryEvdEPe9peOtC10tjxftusryYePePVVrLnrB/l2tobdHDBZrZTxwqYWyYAVt/cOs2XPeFm6b7teGuEbJ8ddHuRHcza3cqnFNu3aRTrnRPtQtePrT0aXAD7/luOxAaRLnPPpwFE10vna7nHdo37GFXVXPR8+7mXV3O+wf8YQvcsRAueMZ95uFGqnc9Dx5OctUs3sbjhIa7G2DipzDn/+D5OFj7lfu5dR7h/ZrBDVxJQotd+0tpa790T9glvZvSNrlSqrdp149V07bu72DTnLJdancsgZ9fdDMRnDQMTr/fNQxPf8C1kfUaU/Ym3rilqy69c7Erraz/2v2Nrnjf/W23G+SqCq94y1OKvt0FoH2bqy8vx+HECEfmxNOqd9m6/+w0948af3PZSesA+lzhzv/wOlePfsPX0P5U79dd6/lnH/u2G+RXkAOrP3GDljqc7umW94y7gV/1Ibx5Abx7qZs+Ysv3rnfMRc+5NRUq0/NS2LPWPeV2PMMt2fnyYPjyHlcd8O1j0KyLW5wnMNhVcXx5N8z6sytFnHaPa2fYOs9VK4VGuJ5AJY3CJUIbu8bTBS8DCmf+rvI0BQS66pVfZroSj7cnwW3zIWmBu0GXnh03PBomfFf5tY9VYJArGRyN0MaHP97velj6lgva3S+CYY8cGvFdmZY9XVXjmmkQf5PbV1QA0//gnqJDwt0Kfmu9VAtVh/ibXbvHzIfdA8r2n101YHhLt/QrQFiE6xTx9f1uu08lkz026+Sqpg6nx2hYP92tLf7BdW7NkJIG66RFriqt4xkw9KFDa5z7mJUIjHeterv63pKui4tfh6L8yp9IW3SDW2a7G8Xh+lWvneaK49Fd3XZwAzjtbneTT1rkiv5717upEpq2heu/dDfi7T/DBf+GyyYdPgiAe9+lr7h/ppLtc55wpZV3x7gG5nP/eujGHtHaTdN900yXj28fdVU+KSug+8Vw7afuic+bQRMOVSccaQ3sk0e60keylxlCC3Jh2t1umvC6PB9WTD+4dBJM+N5VlxwpCID7+fUY7do/SibMWzvNBYHWcTDvn7D+G/e30aafG6dRnUoWfCrMgxkPupLmyee7tpWwJofO63c9RHeH5l1dOo6VCHS7AMb811VLfnWfq65MXuL+PiXAdbV9aYALFofrkltNrERgvGvZy9Xfp65z6yj/9Lx7EmvpdRE5J7Sx+4de9YmrYil/w96fCtt+ctMglBZ/k6t//e5J13DcrAv0uMQdi2zvbip5mRDV8djz0/8m99S35XvXEOvtpt1usAs8u1a5vER2OPJ1Izu4RsOsnZWvN12i0wg3S+r6byqWmL5/0gWoaz87VLdcF4m4NbqPVveL3d/A+ulumvgFr0BkR7hxBrwxCj65xY2IPvvx6k6x07yzKxkGBLrSibduoIFBcP00939RHd1Eu5ztShlz/+ZKZsunuK83THcPKT8+B4tfc21lV3/s066pViIw3rXq477uWuX+UIvyXQPhkfQe6wZCrf+m4rF1X7m64O4Xl90f0sg1HG6a7bp9nvlA2aqRRs2OLwjAoae+TsNh1D8P/0/VqnfVgkCJSya6vvRHEhYBHU6r2E6Qstx1d+x7TdUaf+ujNn1daWjNNPdknLzYNcyGNHTViCVVaeX/dqpTdFdXtXO4v43wFlXrEFFVZzwAXc5z1YuhTdyDSJMY9zkj/+56jW2c5cZn+JAFAuNdVEfXlXDVh26agoG3HJrC4HDan+YGK638sOKxNV+4LpfeShUDboGwpu4psNflFY9Xh2ad3BN3VaorjkZJX/uq6DrKjXpO2+S2iwpct8NG0XDu36o3XXWJCPS42DXazvunqw7se7U7Ftkerv7E9fyqyt9gXRIQAJd5Bgze8GXFaq+BE1wvqRkPee+WWl3J8NmVTd0WEOhumFvmuX/K8tU5lb4vwPWo2DS77IC0A/vctXpc7P2mGRbh6uKvnHrCdKnziZM9VVIbZrh/7LcvcT1hLvx32X77/qjHaCgucD+bvteUbZiO7X+o+2990yDS9azyVgoNCHBdhgtyXI8lH7FAYCpX0j9/6B+OrndJn7GuHjXx00P71k8HLTp817+Y/q6xtj6L7OAaHJe8Ca+e4bopXjLRNR76u5h4aNwGEPckbJzorjDsQdeAXjKSvZpZIDCV6z3WvQbccnTva9nL3exKD7lfM80Ve0tWEfNnJ4901UOhjV1Pq5IBYv4uIADOetgNtjreNqH65tS7XRVRdqpPLu/TMriIjASeBwKB11X1yUrOGwAsAMap6se+TJM5Cu2HuNfREnH9rGf/xXV/277ADRA79a46OylXtRpyp6sOiL/pyP3y/U1d7jrrS4HBrgdVdSxN64XPSgQiEgi8BIwCegBXikiFVjrPeU/hFrk39UXvsRAY6kaHNu/i5pY569HaTtWJoVFz1zhoQcAcDR8FAfBtiWAgsFFVNwOIyFRgNFB++ai7gE+AAT5Mi6lpTdvC79a5hub63PhrTD3gyzaCGCCp1HayZ99BIhIDXApMPNyFRGSCiCSISEJqqm/qyIwPNIyyIGBMHeDLQOCtMrj8un3PAQ+q6mEXwFXVSaoar6rx0dHR1ZZAY4wxvq0aSgbaltqOBVLKnRMPTBXXgNgcOF9EClX1cx+myxhjTCm+DASLgS4i0hHYAYwHrip9gqoe7CMmIm8CX1kQMMaYmuWzQKCqhSJyJ643UCAwWVUTReRWz/HDtgsYY4ypGT5tyVPV6cD0cvu8BgBVvcGXaTHGGOOdjSw2xhg/Z4HAGGP8nAUCY4zxcxYIjDHGz1kgMMYYP2eBwBhj/JwFAmOM8XMWCIwxxs9ZIDDGGD9ngcAYY/ycTRZvjKlTCgoKSE5OJjc3t7aTckIKCwsjNjaW4ODgKr/HAoExpk5JTk6mcePGdOjQAbE1sMtQVdLS0khOTqZjx45HfoOHVQ0ZY+qU3NxcmjVrZkHACxGhWbNmR11askBgjKlzLAhU7lh+NhYIjDHGz1kgMMYYP2eBwBhj/Jz1GjLG1FlPfJnImpTMar1mjzYR/Pminkc875JLLiEpKYnc3FzuueceJkyYwIwZM3jkkUcoKiqiefPmzJ49m/3793PXXXeRkJCAiPDnP/+ZMWPGVGuaj5dPA4GIjASex61Z/LqqPlnu+Gjgr0AxUAjcq6o/+jJNxhhTHSZPnkxUVBQ5OTkMGDCA0aNHc8sttzBv3jw6duzIvn37APjrX/9KkyZNWLVqFQC//vprbSbbK58FAhEJBF4CzgGSgcUiMk1V15Q6bTYwTVVVRPoAHwLdfJUmY0z9UpUnd1/5z3/+w2effQZAUlISkyZN4swzzzzYfz8qKgqAWbNmMXXq1IPvi4yMrPnEHoEv2wgGAhtVdbOq5gNTgdGlT1DV/aqqns1GgGKMMSe47777jlmzZvHzzz+zYsUK+vbtS1xcnNeum6p6wnd39WUgiAGSSm0ne/aVISKXisg64GvgJh+mxxhjqkVGRgaRkZE0bNiQdevWsWDBAvLy8vj+++/ZsmULwMGqoXPPPZcXX3zx4HtPxKohXwYCbyGwwhO/qn6mqt2AS3DtBRUvJDJBRBJEJCE1NbWak2mMMUdn5MiRFBYW0qdPHx577DEGDx5MdHQ0kyZN4rLLLiMuLo5x48YB8Mc//pFff/2VXr16ERcXx9y5c2s59RX5srE4GWhbajsWSKnsZFWdJyKdRKS5qu4td2wSMAkgPj7eqo+MMbUqNDSUb775xuuxUaNGldkODw/nrbfeqolkHTNflggWA11EpKOIhADjgWmlTxCRzuKpPBORfkAIkObDNBljjCnHZyUCVS0UkTuBmbjuo5NVNVFEbvUcnwiMAa4TkQIgBxhXqvHYGGNMDfDpOAJVnQ5ML7dvYqnvnwKe8mUajDHGHJ5NMWGMMX7OAoExxvg5CwTGGOPnLBAYY4yfs0BgjDE+FB4eXttJOCKbhtoYU3d98xDsWlW912zVG0Y9eeTz6hErERhjzFF48MEHefnllw9uP/744zzxxBOMGDGCfv360bt3b7744osqXWv//v2Vvu/tt9+mT58+xMXFce211wKwe/duLr30UuLi4oiLi2P+/PnVkylVrVOv/v37qzHGf61Zs6ZWP3/p0qV65plnHtzu3r27btu2TTMyMlRVNTU1VTt16qTFxcWqqtqoUaNKr1VQUOD1fatXr9auXbtqamqqqqqmpaWpqurYsWP12WefVVXVwsJCTU9P93pdbz8jIEErua9a1ZAxxhyFvn37smfPHlJSUkhNTSUyMpLWrVtz3333MW/ePAICAtixYwe7d++mVatWh72WqvLII49UeN+cOXO4/PLLad68OXBobYM5c+bw9ttvAxAYGEiTJk2qJU8WCIwx5ihdfvnlfPzxx+zatYvx48czZcoUUlNTWbJkCcHBwXTo0IHc3NwjXqey92kNr2FgbQTGGHOUxo8fz9SpU/n444+5/PLLycjIoEWLFgQHBzN37ly2bdtWpetU9r4RI0bw4Ycfkpbm5uAsWdtgxIgRvPLKKwAUFRWRmVk96zVbIDDGmKPUs2dPsrKyiImJoXXr1lx99dUkJCQQHx/PlClT6NataivuVva+nj178uijjzJ06FDi4uK4//77AXj++eeZO3cuvXv3pn///iQmJlZLfkTr2GSf8fHxmpCQUNvJMMbUkrVr19K9e/faTsYJzdvPSESWqGq8t/OtRGCMMX7OGouNMcbHVq1adXAsQInQ0FAWLlxYSykqywKBMabOqeleNcerd+/eLF++vEY+61iq+61qyBhTp4SFhZGWlnZMN7z6TlVJS0sjLCzsqN5nJQJjTJ0SGxtLcnIyqamptZ2UE1JYWBixsbFH9R4LBMaYOiU4OJiOHTvWdjLqFZ9WDYnISBFZLyIbReQhL8evFpGVntd8EYnzZXqMMcZU5LNAICKBwEvAKKAHcKWI9Ch32hZgqKr2Af4KTPJVeowxxnjnyxLBQGCjqm5W1XxgKjC69AmqOl9Vf/VsLgCOrmLLGGPMcfNlG0EMkFRqOxkYdJjzbwa+8XZARCYAEzyb+0Vk/TGmqTmw9xjfW5f5Y779Mc/gn/n2xzzD0ee7fWUHfBkIvHXy9drfS0TOwgWC070dV9VJVEO1kYgkVDbEuj7zx3z7Y57BP/Ptj3mG6s23LwNBMtC21HYskFL+JBHpA7wOjFLVNB+mxxhjjBe+bCNYDHQRkY4iEgKMB6aVPkFE2gGfAteq6gYfpsUYY0wlfFYiUNVCEbkTmAkEApNVNVFEbvUcnwj8CWgGvOwZLl7o4yKev/ZK8sd8+2OewT/z7Y95hmrMd52bhtoYY0z1srmGjDHGz1kgMMYYP+c3geBI013UByLSVkTmishaEUkUkXs8+6NE5H8i8ovna2Rtp7W6iUigiCwTka882/6Q56Yi8rGIrPP8zof4Sb7v8/x9rxaR90UkrL7lW0Qmi8geEVldal+leRSRhz33tvUict7Rfp5fBIIqTndRHxQCv1PV7sBg4A5PPh8CZqtqF2C2Z7u+uQdYW2rbH/L8PDBDVbsBcbj81+t8i0gMcDcQr6q9cB1RxlP/8v0mMLLcPq959PyPjwd6et7zsueeV2V+EQiownQX9YGq7lTVpZ7vs3A3hhhcXt/ynPYWcEntpNA3RCQWuAA3HqVEfc9zBHAm8F8AVc1X1XTqeb49goAGIhIENMSNT6pX+VbVecC+crsry+NoYKqq5qnqFmAj7p5XZf4SCLxNdxFTS2mpESLSAegLLARaqupOcMECaFF7KfOJ54A/AMWl9tX3PJ8EpAJveKrEXheRRtTzfKvqDuAZYDuwE8hQ1W+p5/n2qCyPx31/85dAUOXpLuoDEQkHPgHuVdXM2k6PL4nIhcAeVV1S22mpYUFAP+AVVe0LZFP3q0OOyFMvPhroCLQBGonINbWbqlp33Pc3fwkEVZruoj4QkWBcEJiiqp96du8Wkdae462BPbWVPh84DbhYRLbiqvyGi8i71O88g/ubTlbVktXPP8YFhvqe77OBLaqaqqoFuJkJTqX+5xsqz+Nx39/8JRAccbqL+kDc8Oz/AmtV9d+lDk0Drvd8fz3wRU2nzVdU9WFVjVXVDrjf6xxVvYZ6nGcAVd0FJInIyZ5dI4A11PN846qEBotIQ8/f+whcW1h9zzdUnsdpwHgRCRWRjkAXYNFRXVlV/eIFnA9sADYBj9Z2enyUx9NxRcKVwHLP63zcNB6zgV88X6NqO60+yv8w4CvP9/U+z8ApQILn9/05EOkn+X4CWAesBt4BQutbvoH3cW0gBbgn/psPl0fgUc+9bT1uAs+j+jybYsIYY/ycv1QNGWOMqYQFAmOM8XMWCIwxxs9ZIDDGGD9ngcAYY/ycBQJjyhGRIhFZXupVbSN2RaRD6RkljTkR+HLxemPqqhxVPaW2E2FMTbESgTFVJCJbReQpEVnkeXX27G8vIrNFZKXnazvP/pYi8pmIrPC8TvVcKlBEXvPMqf+tiDSotUwZgwUCY7xpUK5qaFypY5mqOhB4ETfrKZ7v31bVPsAU4D+e/f8BvlfVONw8QIme/V2Al1S1J5AOjPFxfow5LBtZbEw5IrJfVcO97N8KDFfVzZ7J/XapajMR2Qu0VtUCz/6dqtpcRFKBWFXNK3WNDsD/1C0ugog8CASr6v/5PmfGeGclAmOOjlbyfWXneJNX6vsirK3O1DILBMYcnXGlvv7s+X4+buZTgKuBHz3fzwZug4NrKkfUVCKNORr2JGJMRQ1EZHmp7RmqWtKFNFREFuIeoq707LsbmCwiv8etGnajZ/89wCQRuRn35H8bbkZJY04o1kZgTBV52gjiVXVvbafFmOpkVUPGGOPnrERgT4oBJAAAAClJREFUjDF+zkoExhjj5ywQGGOMn7NAYIwxfs4CgTHG+DkLBMYY4+f+H5QqRZat/G5kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['val_acc'], label = 'val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.2, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(validate_images,  validate_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5880207  1.5323483 -2.6163125]\n"
     ]
    }
   ],
   "source": [
    "class_pred = model.predict(test_images,batch_size=16)\n",
    "print(class_pred[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred=np.argmax(class_pred,axis=1)\n",
    "df2[\"pred_res\"]=labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True False False False  True  True  True  True\n",
      " False  True False False  True  True  True  True  True  True  True  True\n",
      "  True False  True False False  True  True  True False False False False\n",
      "  True False False False False False False  True False False False  True\n",
      " False False  True  True  True  True  True False  True  True  True False\n",
      " False False  True False False False  True  True  True  True  True  True\n",
      " False  True False  True False False False False False False  True  True\n",
      "  True  True False False  True  True False  True  True  True  True  True\n",
      " False  True  True False  True  True False False False  True False False\n",
      " False  True  True False False  True  True  True False False  True False\n",
      " False  True False  True False False False  True  True False  True  True\n",
      " False  True  True False False False False  True  True  True  True  True\n",
      "  True  True  True False  True  True False  True  True False False False\n",
      " False  True False False False False False False False  True False  True\n",
      " False False False False False False False False  True  True False  True\n",
      "  True False False  True  True False False False  True  True False  True\n",
      " False False False  True  True False  True  True  True  True  True  True\n",
      " False  True False False False  True False False False False  True  True\n",
      "  True  True False False False False  True  True False  True  True  True\n",
      "  True  True False  True  True  True False  True  True  True  True False\n",
      " False False False  True  True  True  True  True  True False False False\n",
      "  True False False  True  True  True False  True False False  True False\n",
      " False False  True  True  True  True  True  True False  True  True  True\n",
      "  True  True False  True  True False  True  True  True False  True  True\n",
      " False False False False  True  True  True  True False  True  True  True\n",
      "  True False  True False  True False]\n",
      "Numbers of correct prediction:163\n",
      "Accuracy:53.267974\n"
     ]
    }
   ],
   "source": [
    "correct=(labels_pred == test_labels.argmax(axis=1))\n",
    "print(correct)\n",
    "print(\"Numbers of correct prediction:%d\" %sum(correct))\n",
    "a =len(correct)\n",
    "print(\"Accuracy:%f\" %((sum(correct)*100)/a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date : 0, cost : -174.550003,buy_c:1,price:174.550003 Buy\n",
      "date : 100, cost :3.1499939999999924,buy_c:0,price:177.699997 Sell\n",
      "date : 104, cost : -171.20001200000002,buy_c:1,price:174.350006 Buy\n",
      "date : 130, cost :5.449981999999977,buy_c:0,price:176.649994 Sell\n",
      "date : 131, cost : -169.45001200000002,buy_c:1,price:174.899994 Buy\n",
      "date : 140, cost :14.149993999999992,buy_c:0,price:183.600006 Sell\n",
      "date : 142, cost : -170.25,buy_c:1,price:184.399994 Buy\n",
      "date : 143, cost :23.600006000000008,buy_c:0,price:193.850006 Sell\n",
      "date : 144, cost : -167.449997,buy_c:1,price:191.050003 Buy\n",
      "date : 149, cost :28.949996999999996,buy_c:0,price:196.399994 Sell\n",
      "date : 151, cost : -166.800003,buy_c:1,price:195.75 Buy\n",
      "date : 152, cost :33.5,buy_c:0,price:200.300003 Sell\n",
      "date : 153, cost : -164.0,buy_c:1,price:197.5 Buy\n",
      "-164.0\n",
      "7\n",
      "6\n",
      "win: 6\n",
      "loss: 0\n"
     ]
    }
   ],
   "source": [
    "df2['prediction']=labels_pred\n",
    "icost=[]\n",
    "buy_l=[]\n",
    "cost=0\n",
    "buy_c=0\n",
    "buy=0\n",
    "sell=0\n",
    "win=0\n",
    "loss=0\n",
    "\n",
    "for i in df2.index:\n",
    "    if(df2['prediction'][i]==0):\n",
    "        if(buy_c<=0):\n",
    "            buy_c=buy_c+1\n",
    "            buy=buy+1\n",
    "            cost=cost - df2['Adj Close'][i]\n",
    "            x=df2['Adj Close'][i]\n",
    "            #print(cost)\n",
    "            buy_l.append(x)\n",
    "            print(\"date : {}, cost : {},buy_c:{},price:{}\".format(i, cost,buy_c,x),'Buy')\n",
    "    if(df2['prediction'][i]==2):\n",
    "        y=df2['Adj Close'][i]\n",
    "        if(buy_c>=1):\n",
    "            if(y-x>0):\n",
    "                buy_c=buy_c-1\n",
    "                sell=sell+1\n",
    "                cost=cost+df2['Adj Close'][i]\n",
    "                print(\"date : {}, cost :{},buy_c:{},price:{}\".format(i, cost,buy_c,y),\"Sell\")\n",
    "                if((buy>0) & (sell>0)):\n",
    "                    if(y-x<0):\n",
    "                        loss=loss+1\n",
    "                    if(y-x>0):\n",
    "                        win=win+1\n",
    "                    icost.append(y-x)\n",
    "    if(df2['prediction'][i]==1):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "print(cost)\n",
    "#print((cost-icost)/icost)\n",
    "print(buy)\n",
    "print(sell)\n",
    "print(\"win:\",win)\n",
    "print('loss:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes=df2[\"prediction\"]\n",
    "testy=df2[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.532680\n",
      "Precision: 0.515297\n",
      "Recall: 0.509717\n",
      "F1 score: 0.510155\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(testy, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(testy, yhat_classes ,average='macro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(testy, yhat_classes,average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(testy, yhat_classes,average='macro')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[87 26 14]\n",
      " [30 32 22]\n",
      " [29 22 44]]\n",
      "Accuracy Score : 0.5326797385620915\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64       127\n",
      "           1       0.40      0.38      0.39        84\n",
      "           2       0.55      0.46      0.50        95\n",
      "\n",
      "    accuracy                           0.53       306\n",
      "   macro avg       0.52      0.51      0.51       306\n",
      "weighted avg       0.53      0.53      0.53       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(testy, yhat_classes) \n",
    "  \n",
    "print ('Confusion Matrix :')\n",
    "print(results) \n",
    "print ('Accuracy Score :',accuracy_score(testy, yhat_classes))\n",
    "print(\"Report\")\n",
    "print (classification_report(testy, yhat_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
